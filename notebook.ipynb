{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "WaveGan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mostafaelaraby/wavegan-pytorch/blob/master/notebook.ipynb)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning Repo and setup of dependencies"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "GYMymOZmXP05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/Vakihito/wavegan-pytorch.git"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "colab_type": "code",
        "id": "UMvZjUddXAte",
        "outputId": "6334f2f7-c7ea-4107-e7e5-0e90cccd58fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "os.chdir('wavegan-pytorch')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "daby8oFNXdH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !pip3  install -r requirements.txt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "colab_type": "code",
        "id": "ipSNRqjpXTLD",
        "outputId": "f28244a6-7fb7-4e92-83b2-a8a56b324f29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Data"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "MyaocfY_XkCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bach piano performances"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "RgnM-ulA3fx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget http://deepyeti.ucsd.edu/cdonahue/wavegan/data/mancini_piano.tar.gz"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "colab_type": "code",
        "id": "TdKGCMpnYGP4",
        "outputId": "a8f8adf4-35ef-4ef2-bfa9-57e9dc1409d5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!tar -xvf mancini_piano.tar.gz"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "colab_type": "code",
        "id": "HXZ9erR3Yvw8",
        "outputId": "60fe97dc-3a24-40fa-a87b-be6eaad0a48f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Params"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "SnS4lQeq62gS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cat params.py\r\n",
        "# copy cell content to next cell and edit your params then run "
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eImpOc6i64KU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile params.py\r\n",
        "import torch\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import logging\r\n",
        "import os\r\n",
        "\r\n",
        "#############################\r\n",
        "# DataSet Path\r\n",
        "#############################s\r\n",
        "target_signals_dir = 'piano'\r\n",
        "#############################\r\n",
        "# Model Params\r\n",
        "#############################\r\n",
        "model_prefix = 'test' # name of the model to be saved\r\n",
        "n_iterations = 100000\r\n",
        "lr_g = 1e-4\r\n",
        "lr_d = 3e-4 # you can use with discriminator having a larger learning rate than generator instead of using n_critic updates ttur https://arxiv.org/abs/1706.08500\r\n",
        "beta1 = 0.5\r\n",
        "beta2 = 0.9\r\n",
        "use_batchnorm=False\r\n",
        "validate=True\r\n",
        "decay_lr = False # used to linearly deay learning rate untill reaching 0 at iteration 100,000\r\n",
        "generator_batch_size_factor = 1 # in some cases we might try to update the generator with double batch size used in the discriminator https://arxiv.org/abs/1706.08500\r\n",
        "n_critic = 1 # update generator every n_critic steps if lr_g = lr_d the n_critic's default value is 5 \r\n",
        "# gradient penalty regularization factor.\r\n",
        "p_coeff = 10\r\n",
        "batch_size = 10\r\n",
        "noise_latent_dim = 100  # size of the sampling noise\r\n",
        "model_capacity_size = 32    # model capacity during training can be reduced to 32 for larger window length of 2 seconds and 4 seconds\r\n",
        "# rate of storing validation and costs params\r\n",
        "store_cost_every = 300\r\n",
        "progress_bar_step_iter_size = 400\r\n",
        "#############################\r\n",
        "# Backup Params\r\n",
        "#############################\r\n",
        "take_backup = True\r\n",
        "backup_every_n_iters = 1000\r\n",
        "save_samples_every = 1000\r\n",
        "output_dir = 'output'\r\n",
        "if not(os.path.isdir(output_dir)):\r\n",
        "    os.makedirs(output_dir)\r\n",
        "#############################\r\n",
        "# Audio Reading Params\r\n",
        "#############################\r\n",
        "window_length = 65536 #[16384, 32768, 65536] in case of a longer window change model_capacity_size to 32\r\n",
        "sampling_rate = 16000\r\n",
        "normalize_audio = True \r\n",
        "num_channels = 1\r\n",
        "\r\n",
        "#############################\r\n",
        "# Logger init\r\n",
        "#############################\r\n",
        "LOGGER = logging.getLogger('wavegan')\r\n",
        "LOGGER.setLevel(logging.DEBUG)\r\n",
        "#############################\r\n",
        "# Torch Init and seed setting\r\n",
        "#############################\r\n",
        "cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\r\n",
        "# update the seed\r\n",
        "manual_seed = 2019 \r\n",
        "random.seed(manual_seed)\r\n",
        "torch.manual_seed(manual_seed)\r\n",
        "np.random.seed(manual_seed)\r\n",
        "if cuda:\r\n",
        "    torch.cuda.manual_seed(manual_seed)\r\n",
        "    torch.cuda.empty_cache()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "F0_YaLJ67nVS",
        "outputId": "dd9ce7a5-2310-41a8-e139-32bdf6fe3e8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "NUo6Kmg3ZPwy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python3  train.py"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "colab_type": "code",
        "id": "V4HQdcGpZL-w",
        "outputId": "8257f56b-fcea-4aab-aae1-df84fb7342cd"
      }
    }
  ]
}